{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import pymysql as MySQLdb\n",
    "import _pickle as cpickle\n",
    "import os\n",
    "\n",
    "\n",
    "author_names_to_process = []\n",
    "max_count = 100000000\n",
    "COUNT = 0\n",
    "last_count = 0\n",
    "for line in open('../AuthorNameIn985.txt',encoding = 'utf-8'):\n",
    "        COUNT += 1\n",
    "        if COUNT % 10000000 == 0:\n",
    "            print (time.now(), COUNT)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        if last_count < COUNT <= max_count:\n",
    "            author_names_to_process.append(line.replace('\\n', ''))\n",
    "        elif COUNT > max_count:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = MySQLdb.connect(host='202.120.36.29', port=3306, user='groupleader', passwd='onlyleaders', db='mag-new-160205',\n",
    "                       charset=\"utf8\")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "class Paper:\n",
    "    def __init__(self, paper_id, title, author_id):\n",
    "        self.paper_id = paper_id\n",
    "        # self.title = title\n",
    "        # self.year = year\n",
    "        # self.venue_id = venue_id\n",
    "        # self.affiliation_id = affiliation_id\n",
    "        # self.coauthors = coauthors\n",
    "        self.author_id = author_id\n",
    "        '''\n",
    "        title_nlp = nlp(unicode(title.encode('utf-8').decode('utf-8')))\n",
    "\n",
    "        title_vector_sum = np.zeros(title_nlp[0].vector.shape)\n",
    "        word_count = 0\n",
    "        self.title_vector = np.zeros(title_nlp[0].vector.shape)\n",
    "\n",
    "        for word in title_nlp:\n",
    "            if str(word) not in stopwords and len(str(word)) > 1:\n",
    "                title_vector_sum += word.vector\n",
    "                word_count += 1\n",
    "        if word_count != 0:\n",
    "            self.title_vector = title_vector_sum / word_count\n",
    "        '''\n",
    "        self.title_vector = [0]\n",
    "\n",
    "class Cluster:\n",
    "    def __init__(self, paper, paper_idx, affiliation_id, year):\n",
    "        # paper = papers[idx]\n",
    "        self.author_id = None\n",
    "        self.papers = list()\n",
    "        self.papers.append(paper)\n",
    "        self.paper_idx_list = list()\n",
    "        self.paper_idx_list.append(paper_idx)\n",
    "        self.cluster_id = paper_idx\n",
    "        self.affiliations = set()\n",
    "        self.affiliations.add(affiliation_id)\n",
    "        self.year_2_affiliations = dict()\n",
    "        if affiliation_id is not None and year is not None:\n",
    "            self.year_2_affiliations[year] = set()\n",
    "            self.year_2_affiliations[year].add(affiliation_id)\n",
    "\n",
    "        self.link_type_2_ngbrs = dict()\n",
    "        self.ngbrs = set()\n",
    "\n",
    "    def unit(self, other, paper_idx_2_cluster_id):\n",
    "        for paper_idx in other.paper_idx_list:\n",
    "            paper_idx_2_cluster_id[paper_idx] = self.cluster_id\n",
    "        self.papers.extend(other.papers)\n",
    "        self.paper_idx_list.extend(other.paper_idx_list)\n",
    "        self.affiliations |= other.affiliations\n",
    "\n",
    "        for k, v in other.year_2_affiliations.iteritems():\n",
    "            if k in self.year_2_affiliations.keys():\n",
    "                self.year_2_affiliations[k] |= v\n",
    "            else:\n",
    "                self.year_2_affiliations[k] = v\n",
    "\n",
    "    def has_no_conflict(self, other, paper_final_edges, strict_mode):\n",
    "        connected_edges = 0\n",
    "        for paper_idx in other.paper_idx_list:\n",
    "            connected_edges += len(np.nonzero(paper_final_edges[paper_idx, self.paper_idx_list])[0])\n",
    "\n",
    "        if strict_mode and float(connected_edges) < 0.01 * (len(self.papers) * len(other.papers)):\n",
    "            return False\n",
    "\n",
    "        if len(self.affiliations | other.affiliations) > 20:\n",
    "            return False\n",
    "\n",
    "        for k, v in self.year_2_affiliations.iteritems():\n",
    "            if k in other.year_2_affiliations.keys():\n",
    "                if len(v | other.year_2_affiliations[k]) > 3:\n",
    "                    return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "def get_paper_affiliations_by_author_name(author_name):\n",
    "    #select stuname as '姓名',classname as '班级' from student inner join c lass on student.stuid=class.stuid\n",
    "    #select stuname as '姓名',classname as '班级'\n",
    "    #from student,class\n",
    "    #where student.stuid=class.stuid\n",
    "    quest_paper_by_author_name = 'SELECT PaperID,AffiliationID,A.AuthorID FROM PaperAuthorAffiliations AS P INNER JOIN ' \\\n",
    "                                 '(SELECT AuthorID FROM Authors WHERE AuthorName =\"%s\") AS A ' \\\n",
    "                                 'ON P.AuthorID = A.AuthorID'\n",
    "    cursor.execute(quest_paper_by_author_name % author_name)\n",
    "    paper_affiliations = cursor.fetchall()\n",
    "    return paper_affiliations\n",
    "\n",
    "\n",
    "def get_coauthors_by_paper_id(paper_id):\n",
    "    quest_author_by_paper = 'SELECT AuthorID FROM PaperAuthorAffiliations WHERE PaperID = \"%s\"'\n",
    "    cursor.execute(quest_author_by_paper % paper_id)\n",
    "    author_ids = cursor.fetchall()\n",
    "    if len(author_ids) > 20:\n",
    "        return None\n",
    "\n",
    "    quest_author_by_paper = 'SELECT AuthorName FROM Authors INNER JOIN ' \\\n",
    "                            '(SELECT AuthorID FROM PaperAuthorAffiliations WHERE PaperID = \"%s\") AS TB ' \\\n",
    "                            'ON Authors.AuthorID = TB.AuthorID'\n",
    "    cursor.execute(quest_author_by_paper % paper_id)\n",
    "    authors = cursor.fetchall()\n",
    "    return authors\n",
    "\n",
    "\n",
    "def get_title_venue_year_by_paper_id(paper_id):\n",
    "    quest_info_by_paper = 'SELECT NormalizedPaperTitle, ConferenceSeriesIDMappedToVenueName, ' \\\n",
    "                          'JournalIDMappedToVenueName, PaperPublishYear FROM Papers WHERE PaperID = \"%s\"'\n",
    "    cursor.execute(quest_info_by_paper % paper_id)\n",
    "    rs = cursor.fetchall()\n",
    "    return rs\n",
    "def add_in_inverted_indices(inverted_indices, paper_idx, feature_uni_id):\n",
    "    if feature_uni_id not in inverted_indices:\n",
    "        inverted_indices[feature_uni_id] = list()\n",
    "    inverted_indices[feature_uni_id].append(paper_idx)# papers about this unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_papers_and_init_clusters(author_name, COUNT):\n",
    "    paper_affiliations = get_paper_affiliations_by_author_name(author_name)\n",
    "\n",
    "    if len(paper_affiliations) < 200 or len(paper_affiliations) > 300:\n",
    "        return None, None, None, None, None\n",
    "    # elif len(paper_affiliations) > 15000:\n",
    "    #     f_big = open('./big_name', 'a')\n",
    "    #     f_big.write(author_name + \"\\n\")\n",
    "    #     f_big.close()\n",
    "    #     return None, None, None, None, None\n",
    "    print (author_name + '\\t',)\n",
    "\n",
    "    process_count = 0\n",
    "    papers = list()\n",
    "    clusters = dict()\n",
    "    paper_idx_2_cluster_id = dict()\n",
    "    inverted_indices = dict()\n",
    "    author_id_set = set()\n",
    "\n",
    "    uni_id_generator = 0\n",
    "    coauthor_2_uni_id = dict()\n",
    "    affiliation_2_uni_id = dict()\n",
    "    venue_2_uni_id = dict()\n",
    "\n",
    "    for paper_affiliation in paper_affiliations:\n",
    "        paper_id = paper_affiliation[0]\n",
    "        original_author_id = paper_affiliation[2]\n",
    "        author_id_set.add(original_author_id)\n",
    "\n",
    "        # get coauthors\n",
    "        authors = get_coauthors_by_paper_id(paper_id)\n",
    "        if authors is None:\n",
    "            continue\n",
    "\n",
    "        paper_idx = process_count\n",
    "\n",
    "        # coauthors = set()\n",
    "        for author in authors:\n",
    "            coauthor_name = author[0]\n",
    "            if coauthor_name != author_name:\n",
    "                if coauthor_name not in coauthor_2_uni_id:\n",
    "                    coauthor_2_uni_id[coauthor_name] = 'a' + str(uni_id_generator)\n",
    "                    uni_id_generator += 1\n",
    "                coauthor_uni_id = coauthor_2_uni_id[coauthor_name]\n",
    "                # coauthors.add(coauthor_uni_id)\n",
    "\n",
    "                add_in_inverted_indices(inverted_indices, paper_idx, coauthor_uni_id)\n",
    "\n",
    "        # get affiliation\n",
    "        affiliation_id = paper_affiliation[1]\n",
    "        if affiliation_id is not None:\n",
    "            if affiliation_id not in affiliation_2_uni_id:\n",
    "                affiliation_2_uni_id[affiliation_id] = 'o' + str(uni_id_generator)\n",
    "                uni_id_generator += 1\n",
    "            affiliation_id = affiliation_2_uni_id[affiliation_id]\n",
    "\n",
    "            add_in_inverted_indices(inverted_indices, paper_idx, affiliation_id)\n",
    "\n",
    "        # get venue, title and year\n",
    "        venue_id = None\n",
    "        title = None\n",
    "        year = None\n",
    "        title_venue_year = get_title_venue_year_by_paper_id(paper_id)\n",
    "        if len(title_venue_year) != 0:\n",
    "            # fill in paper_venue_dict\n",
    "            if title_venue_year[0][1] is not None:\n",
    "                venue_id = title_venue_year[0][1]\n",
    "            elif title_venue_year[0][2] is not None:\n",
    "                venue_id = title_venue_year[0][2]\n",
    "\n",
    "            if venue_id is not None:\n",
    "                if venue_id not in venue_2_uni_id:\n",
    "                    venue_2_uni_id[venue_id] = 'v' + str(uni_id_generator)\n",
    "                    uni_id_generator += 1\n",
    "                venue_id = venue_2_uni_id[venue_id]\n",
    "\n",
    "                add_in_inverted_indices(inverted_indices, paper_idx, venue_id)\n",
    "\n",
    "            title = title_venue_year[0][0]\n",
    "            year = title_venue_year[0][3]\n",
    "\n",
    "        paper_instance = Paper(paper_id, title, original_author_id)\n",
    "        papers.append(paper_instance)\n",
    "\n",
    "        # initially each paper is used as a cluster\n",
    "        new_cluster = Cluster(paper_instance, paper_idx, affiliation_id, year)\n",
    "        clusters[paper_idx] = new_cluster\n",
    "        paper_idx_2_cluster_id[paper_idx] = paper_idx\n",
    "        process_count += 1\n",
    "\n",
    "    if len(clusters) == 0:\n",
    "        print (\"\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    return papers, clusters, paper_idx_2_cluster_id, inverted_indices, author_id_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380833\n"
     ]
    }
   ],
   "source": [
    "print (len(author_names_to_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\t\n",
      "xueqing wang\t\n",
      "0 xueqing wang\n",
      "100\t\n",
      "j c han\t\n",
      "100\t\n",
      "chenyang shen\t\n",
      "100\t\n",
      "jianbin zhang\t\n",
      "100\t\n",
      "shaojie wang\t\n",
      "100\t\n",
      "richard a birdsey\t\n",
      "100\t\n",
      "xu tao\t\n",
      "100\t\n",
      "zhen qin\t\n",
      "100\t\n",
      "z m chen\t\n",
      "100\t\n",
      "ling tao\t\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "save_dir = \"../data/%s/\"\n",
    "\n",
    "for name in author_names_to_process:\n",
    "    papers, clusters, paper_idx_2_cluster_id, inverted_indices, author_id_set = analyze_papers_and_init_clusters(name, 100)\n",
    "    if(papers!= None):\n",
    "        \n",
    "        if(cnt % 1000==0):\n",
    "            print (\"now working on \",cnt,name)\n",
    "        cnt +=1\n",
    "        \n",
    "        save_dir_now = save_dir%name\n",
    "        if(os.path.exists(save_dir_now)==False):\n",
    "            os.makedirs(save_dir_now)\n",
    "            \n",
    "        cpickle.dump(papers,open(os.path.join(save_dir_now,\"papers_%s\"%(name)),'wb'))\n",
    "        cpickle.dump(clusters,open(os.path.join(save_dir_now,\"clusters_%s\"%(name)),'wb'))\n",
    "        cpickle.dump(paper_idx_2_cluster_id,open(os.path.join(save_dir_now,\"paper_idx_2_cluster_id_%s\"%(name)),'wb'))\n",
    "        cpickle.dump(inverted_indices,open(os.path.join(save_dir_now,\"inverted_indices_%s\"%(name)),'wb'))\n",
    "        cpickle.dump(author_id_set,open(os.path.join(save_dir_now,\"author_id_set_%s\"%(name)),'wb'))\n",
    "print (\"over,cnt:\", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Can't find model 'en'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d84f1dc1b8dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/sjtuiiot/ytjia/.pyenv/versions/anaconda3-4.0.0/lib/python3.5/site-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;34m\"to load. For example:\\nnlp = spacy.load('{}')\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             'error')\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/sjtuiiot/ytjia/.pyenv/versions/anaconda3-4.0.0/lib/python3.5/site-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'exists'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can't find model '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Can't find model 'en'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
